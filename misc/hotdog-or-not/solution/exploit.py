import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import save_img
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

import numpy as np
import matplotlib as mpl
mpl.use("tkagg")
import matplotlib.pyplot as plt

def deprocess(x):
    x = x[0]
    if isinstance(x, tf.Tensor):
        x = x.numpy()
    x = ((x + 1.0) * 127.5).astype(np.uint8)
    return x

from PIL import Image
import cv2
import tifffile

def save_and_test_formats(adv_array, model, expected_confidence):
    img = adv_array[0]
    img_255 = ((img + 1.0) * 127.5)
    print(f"expected confidence: {expected_confidence:.10f}\n")
    
    results = {}
    
    img_uint8 = np.clip(img_255, 0, 255).astype(np.uint8)
    Image.fromarray(img_uint8).save('test_8bit.png')
    img_uint16 = np.clip(img_255 * 256, 0, 65535).astype(np.uint16)
    cv2.imwrite('test_16bit.png', cv2.cvtColor(img_uint16, cv2.COLOR_RGB2BGR))
    tifffile.imwrite('test_float32.tiff', img_255.astype(np.float32))
    tifffile.imwrite('test_uint16.tiff', img_uint16)
    Image.fromarray(img_uint8).save('test.bmp')
    Image.fromarray(img_uint8).save('test.ppm')
    cv2.imwrite('test_jp2.jp2', cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR), [cv2.IMWRITE_JPEG2000_COMPRESSION_X1000, 0])  # 0 = lossless
    Image.fromarray(img_uint8).save('test_lossless.webp', lossless=True)
    
    formats = [
        ('PNG 8-bit', 'test_8bit.png', 'PIL'),
        ('PNG 16-bit', 'test_16bit.png', 'cv2'),
        ('TIFF float32', 'test_float32.tiff', 'tiff'),
        ('TIFF uint16', 'test_uint16.tiff', 'tiff'),
        ('BMP', 'test.bmp', 'PIL'),
        ('PPM', 'test.ppm', 'PIL'),
        ('JPEG2000 lossless', 'test_jp2.jp2', 'cv2'),
        ('WebP lossless', 'test_lossless.webp', 'PIL')
    ]
    
    for fmt_name, filepath, loader in formats:
        try:
            if loader == 'PIL':
                img_loaded = Image.open(filepath)
                img_array = np.array(img_loaded)
            elif loader == 'cv2':
                img_array = cv2.imread(filepath)
                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
                if '16bit' in filepath:
                    img_array = img_array.astype(np.float32) / 256.0
            elif loader == 'tiff':
                img_array = tifffile.imread(filepath)
                if img_array.dtype == np.float32:
                    img_array = img_array
                elif img_array.dtype == np.uint16:
                    img_array = img_array.astype(np.float32) / 256.0
            
            if img_array.dtype != np.float32:
                img_array = img_array.astype(np.float32)
            
            if img_array.max() > 2.0:
                x = preprocess_input(img_array)
            else:
                x = (img_array / 127.5) - 1.0
                
            x = np.expand_dims(x, axis=0)
            pred = model.predict(x, verbose=0)
            confidence = np.max(pred)
            diff = abs(confidence - expected_confidence)
            
            results[fmt_name] = {
                'confidence': confidence,
                'difference': diff,
                'bits': '32' if 'float' in filepath else '16' if '16' in filepath else '8'
            }
            
            print(f"{fmt_name:20} | confidence: {confidence:.10f} | diff: {diff:.10f} | {'✓' if diff < 1e-6 else '✗'}")
            
        except Exception as e:
            print(f"{fmt_name:20} | error: {str(e)}")
    
    return results


def save_adversarial_best_format(adv_array, filepath):
    img = adv_array[0]
    img_255 = ((img + 1.0) * 127.5)
    
    if filepath.endswith('.tiff') or filepath.endswith('.tif'):
        tifffile.imwrite(filepath, img_255.astype(np.float32))
    
    elif filepath.endswith('.png'):
        img_uint8 = np.clip(img_255, 0, 255).astype(np.uint8)
        img_uint16 = np.clip(img_255 * 256, 0, 65535).astype(np.uint16)
        
        loss_8bit = np.mean(np.abs(img_255 - img_uint8))
        loss_16bit = np.mean(np.abs(img_255 - img_uint16/256.0))
        
        if loss_16bit < loss_8bit * 0.1:
            cv2.imwrite(filepath, cv2.cvtColor(img_uint16, cv2.COLOR_RGB2BGR))
        else:
            Image.fromarray(img_uint8).save(filepath)
    
    elif filepath.endswith('.bmp'):
        img_uint8 = np.clip(img_255, 0, 255).astype(np.uint8)
        Image.fromarray(img_uint8).save(filepath)

# exploit start
model = load_model('../challenge/model/mt_classifier_ft_0.h5')

img_path = "../challenge/hotdog.png"
img = image.load_img(img_path, target_size=(224, 224))

x = image.img_to_array(img)
x = preprocess_input(x)
x_input = np.expand_dims(x, axis=0)

pred_orig = model.predict(x_input, verbose=0)
label_orig = np.argmax(pred_orig)

"""
[Adversarial] Class: 101 → FLAG!
[+] Mean pixel difference: 0.004093505907803774
[+] Max pixel difference: 0.09541630744934082
[+] L2 perturbation distance: 2.5686938762664795
[+] Confience: 0.9914597272872925
[+] Confidence: 0.9914597272872925
"""

#""" try1
#c_weight = 43.2
c_weight = 53.5882568359375
learning_rate = 0.005
target_label = 101
target_label = target_class = 101
num_iterations = 1800
#"""

# 1761 NEW MIN: 2.9247844 -> 2.5686939 0.9914597

min_l2 = 500

# attack
w = tf.Variable(tf.zeros_like(x_input), trainable=True)
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

pred_success = False

for i in range(num_iterations):
    with tf.GradientTape() as tape:
        x_adv = tf.tanh(x_input + w)
        #x_adv = x_input + w
        logits = model(x_adv)

        l2_loss = tf.reduce_sum(tf.square(x_adv - x_input))
        real = logits[:, target_label]
        other = tf.reduce_max(tf.concat([logits[:, :target_class], logits[:, target_class+1:]], axis=1), axis=1)
        f_loss = tf.maximum(0.0, other - real + 0.5)
        loss = l2_loss + c_weight * f_loss

    grads = tape.gradient(loss, w)
    optimizer.apply_gradients([(grads, w)])

    pred_label = np.argmax(logits.numpy())
    l2_distance = tf.norm(x_adv - x_input).numpy()

    #print(pred_label)
    if pred_label == target_label:
        pred_success = True
        #print(pred_label, [c_weight, learning_rate, i, l2_distance], np.max(model.predict(x_adv, verbose=0)))

        if l2_distance < min_l2 and np.max(model.predict(x_adv, verbose=0)) > 0.99:
            print(i, "NEW MIN:", min_l2, "->", l2_distance, np.max(model.predict(x_adv, verbose=0)))
            min_l2 = l2_distance
            best_adv = x_adv.numpy()
            best_w = w.numpy()
            successful_step = True

with open("../challenge/train_dataset/meta/labels.txt") as f:
    class_names = [line.strip() for line in f]

#pred_adv = model.predict(x_adv, verbose=0)
pred_adv = model.predict(best_adv, verbose=0)
label_adv = np.argmax(pred_adv)

label_name_orig = class_names[label_orig]
label_name_adv = class_names[label_adv]

#adv_np = x_adv.numpy()
adv_np = best_adv
diff_pixels = np.abs(adv_np - x_input)
l2_distance = np.linalg.norm((adv_np - x_input).flatten())

print(f"[Original] Class: {label_orig} → {label_name_orig}")
print(f"[Adversarial] Class: {label_adv} → {label_name_adv}")
print(f"[+] Mean pixel difference: {diff_pixels.mean()}")
print(f"[+] Max pixel difference: {diff_pixels.max()}")
#print(f"[+] L2 perturbation distance: {l2_distance}")
print(f"[+] L2 perturbation distance: {min_l2}")
print(f"[+] Confience: {np.max(pred_adv)}")
print(f"[+] Confidence: {np.max(model.predict(adv_np, verbose=0))}")

save_and_test_formats(best_adv, model, np.max(model.predict(adv_np, verbose=0))) 

save_adversarial_best_format(best_adv, 'adv.tiff')
save_adversarial_best_format(best_adv, 'adv.png')
save_adversarial_best_format(best_adv, 'adv.bmp')

plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.title(f"Original: {label_name_orig}")
org_image = deprocess(x_input)
plt.imshow(deprocess(x_input))
plt.axis("off")

plt.subplot(1, 3, 2)
plt.title(f"Adversarial: {label_name_adv}")
adv_image = deprocess(adv_np)
save_img('out/adv.png', adv_image)
plt.imshow(deprocess(adv_np))
plt.axis("off")

plt.subplot(1, 3, 3)
plt.title(f"Perturbation ×10\nL2 = {l2_distance}")
diff = (deprocess(adv_np) - deprocess(x_input)) * 10 + 128
diff_image = np.clip(diff, 0, 255).astype(np.uint8)
save_img('out/diff.png', diff_image)
plt.imshow(np.clip(diff, 0, 255).astype(np.uint8))
plt.axis("off")

plt.tight_layout()
plt.savefig('out/result.png')
plt.show()
